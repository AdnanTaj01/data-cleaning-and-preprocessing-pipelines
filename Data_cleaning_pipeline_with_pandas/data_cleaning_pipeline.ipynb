{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb71be0",
   "metadata": {},
   "source": [
    "## Loan Data Cleaning Pipeline\n",
    "Complete Data Cleaning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978971a",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80602ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported Successfully âœ…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries Imported Successfully âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e149aa6",
   "metadata": {},
   "source": [
    "### Step 2: Load Dataset\n",
    "\n",
    "If your file is uploaded manually in Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7892cd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('loan_prediction.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ffefa",
   "metadata": {},
   "source": [
    "### Step 3: Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6879a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "Rows: 614, Columns: 13\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    str    \n",
      " 1   Gender             601 non-null    str    \n",
      " 2   Married            611 non-null    str    \n",
      " 3   Dependents         599 non-null    str    \n",
      " 4   Education          614 non-null    str    \n",
      " 5   Self_Employed      582 non-null    str    \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    str    \n",
      " 12  Loan_Status        614 non-null    str    \n",
      "dtypes: float64(4), int64(1), str(8)\n",
      "memory usage: 62.5 KB\n",
      "\n",
      "Summary Statistics:\n",
      "         Loan_ID Gender Married Dependents Education Self_Employed  \\\n",
      "count        614    601     611        599       614           582   \n",
      "unique       614      2       2          4         2             2   \n",
      "top     LP001002   Male     Yes          0  Graduate            No   \n",
      "freq           1    489     398        345       480           500   \n",
      "mean         NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "std          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "min          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "25%          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "50%          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "75%          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "max          NaN    NaN     NaN        NaN       NaN           NaN   \n",
      "\n",
      "        ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "count        614.000000         614.000000  592.000000         600.00000   \n",
      "unique              NaN                NaN         NaN               NaN   \n",
      "top                 NaN                NaN         NaN               NaN   \n",
      "freq                NaN                NaN         NaN               NaN   \n",
      "mean        5403.459283        1621.245798  146.412162         342.00000   \n",
      "std         6109.041673        2926.248369   85.587325          65.12041   \n",
      "min          150.000000           0.000000    9.000000          12.00000   \n",
      "25%         2877.500000           0.000000  100.000000         360.00000   \n",
      "50%         3812.500000        1188.500000  128.000000         360.00000   \n",
      "75%         5795.000000        2297.250000  168.000000         360.00000   \n",
      "max        81000.000000       41667.000000  700.000000         480.00000   \n",
      "\n",
      "        Credit_History Property_Area Loan_Status  \n",
      "count       564.000000           614         614  \n",
      "unique             NaN             3           2  \n",
      "top                NaN     Semiurban           Y  \n",
      "freq               NaN           233         422  \n",
      "mean          0.842199           NaN         NaN  \n",
      "std           0.364878           NaN         NaN  \n",
      "min           0.000000           NaN         NaN  \n",
      "25%           1.000000           NaN         NaN  \n",
      "50%           1.000000           NaN         NaN  \n",
      "75%           1.000000           NaN         NaN  \n",
      "max           1.000000           NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "print(\"Dataset Shape:\")\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "print()\n",
    "\n",
    "# Info\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "print()\n",
    "\n",
    "# Summary Statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc74be",
   "metadata": {},
   "source": [
    "### Step 4: Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ab81c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "Credit_History      50\n",
      "Self_Employed       32\n",
      "LoanAmount          22\n",
      "Dependents          15\n",
      "Loan_Amount_Term    14\n",
      "Gender              13\n",
      "Married              3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values summary\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff2a13",
   "metadata": {},
   "source": [
    "### Step 5: Handle Missing Values (Improved Way)\n",
    "\n",
    "âš ï¸ We will NOT use `inplace=True`  \n",
    "âš ï¸ We will NOT modify original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30dfcd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madna\\AppData\\Local\\Temp\\ipykernel_4140\\1138151740.py:5: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  cat_cols = df_clean.select_dtypes(include='object').columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Handled âœ…\n"
     ]
    }
   ],
   "source": [
    "# Create copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Separate columns\n",
    "cat_cols = df_clean.select_dtypes(include='object').columns\n",
    "num_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "for col in cat_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        mode_value = df_clean[col].mode()[0]\n",
    "        df_clean[col] = df_clean[col].fillna(mode_value)\n",
    "\n",
    "# Fill numerical columns with median\n",
    "for col in num_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        median_value = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_value)\n",
    "\n",
    "print(\"Missing Values Handled âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95336d59",
   "metadata": {},
   "source": [
    "### Step 6: Fix Special Column (Dependents)\n",
    "\n",
    "Dependents column contains \"3+\" â†’ we convert it to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695c172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 3+ with 3\n",
    "df_clean['Dependents'] = df_clean['Dependents'].replace('3+', '3')\n",
    "\n",
    "# Convert to numeric\n",
    "df_clean['Dependents'] = pd.to_numeric(df_clean['Dependents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f1d5e",
   "metadata": {},
   "source": [
    "### Step 7: Standardize Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d25524",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, not integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cat_cols:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df_clean[col] = \u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m.strip().str.lower()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mText Standardized âœ…\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\DataAnalytics_projects\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6206\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6200\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6201\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6202\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6203\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6204\u001b[39m ):\n\u001b[32m   6205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\DataAnalytics_projects\\.venv\\Lib\\site-packages\\pandas\\core\\accessor.py:230\u001b[39m, in \u001b[36mAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\DataAnalytics_projects\\.venv\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:194\u001b[39m, in \u001b[36mStringMethods.__init__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28mself\u001b[39m._inferred_dtype = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_categorical = \u001b[38;5;28misinstance\u001b[39m(data.dtype, CategoricalDtype)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_string = \u001b[38;5;28misinstance\u001b[39m(data.dtype, StringDtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\DataAnalytics_projects\\.venv\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:248\u001b[39m, in \u001b[36mStringMethods._validate\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    245\u001b[39m inferred_dtype = lib.infer_dtype(values, skipna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    249\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan only use .str accessor with string values, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    250\u001b[39m     )\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .str accessor with string values, not integer"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].str.strip().str.lower()\n",
    "\n",
    "print(\"Text Standardized âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b4ab0",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Step 8: Convert Categorical Columns to Category Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a479e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "\n",
    "print(\"Data Types Fixed âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60c526",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Step 9: Handle Outliers (Capping at 99%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d49c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols = ['LoanAmount', 'ApplicantIncome']\n",
    "\n",
    "for col in outlier_cols:\n",
    "    if col in df_clean.columns:\n",
    "        upper = df_clean[col].quantile(0.99)\n",
    "        df_clean[col] = np.where(df_clean[col] > upper, upper, df_clean[col])\n",
    "\n",
    "print(\"Outliers Capped âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a003d1",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Step 10: Drop Unnecessary Column\n",
    "\n",
    "Loan_ID is not useful for ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200389e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(columns=['Loan_ID'])\n",
    "\n",
    "print(\"Loan_ID Removed âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc620338",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Step 11: Final Clean Dataset Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Dataset Info:\")\n",
    "df_clean.info()\n",
    "\n",
    "print()\n",
    "print(\"Remaining Missing Values:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458a228",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Step 12: Save Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleaned_loan_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaned Dataset Saved Successfully ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313029f",
   "metadata": {},
   "source": [
    "## ðŸ”¥ BONUS: Final Reusable Pipeline Function\n",
    "\n",
    "If you want everything inside ONE function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_loan_data(df):\n",
    "    \"\"\"\n",
    "    Reusable function to clean loan prediction dataset\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Separate columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Handle missing values\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Fix Dependents column\n",
    "    if 'Dependents' in df.columns:\n",
    "        df['Dependents'] = df['Dependents'].replace('3+', '3')\n",
    "        df['Dependents'] = pd.to_numeric(df['Dependents'])\n",
    "\n",
    "    # Standardize text\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "    # Convert to category\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    # Outlier handling\n",
    "    for col in ['LoanAmount', 'ApplicantIncome']:\n",
    "        if col in df.columns:\n",
    "            upper = df[col].quantile(0.99)\n",
    "            df[col] = np.where(df[col] > upper, upper, df[col])\n",
    "\n",
    "    # Drop Loan_ID\n",
    "    if 'Loan_ID' in df.columns:\n",
    "        df = df.drop(columns=['Loan_ID'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e0bf6",
   "metadata": {},
   "source": [
    "### Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original dataset\n",
    "df = pd.read_csv('loan_prediction.csv')\n",
    "\n",
    "# Apply cleaning function\n",
    "df_clean = clean_loan_data(df)\n",
    "\n",
    "# Verify results\n",
    "print(\"Cleaning completed!\")\n",
    "print(df_clean.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
