{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c1577d",
   "metadata": {},
   "source": [
    "### Now, we will write a Python function to:\n",
    "\n",
    "Standardize column names\n",
    "Remove duplicate rows\n",
    "Clean messy text values\n",
    "Handle missing values (even disguised ones!)\n",
    "Flag weird stuff like constant columns and outliers\n",
    "Prepare your data for modelling by converting text columns smartly\n",
    "Here’s how to write such a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eb4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Borrower_ID              500 non-null    str    \n",
      " 1   Age                      500 non-null    int64  \n",
      " 2   Gender                   500 non-null    str    \n",
      " 3   Employment_Type          500 non-null    str    \n",
      " 4   Monthly_Income           500 non-null    int64  \n",
      " 5   Num_Dependents           500 non-null    int64  \n",
      " 6   Loan_ID                  500 non-null    str    \n",
      " 7   Loan_Amount              500 non-null    int64  \n",
      " 8   Loan_Tenure              500 non-null    int64  \n",
      " 9   Interest_Rate            500 non-null    float64\n",
      " 10  Loan_Type                500 non-null    str    \n",
      " 11  Collateral_Value         500 non-null    float64\n",
      " 12  Outstanding_Loan_Amount  500 non-null    float64\n",
      " 13  Monthly_EMI              500 non-null    float64\n",
      " 14  Payment_History          500 non-null    str    \n",
      " 15  Num_Missed_Payments      500 non-null    int64  \n",
      " 16  Days_Past_Due            500 non-null    int64  \n",
      " 17  Recovery_Status          500 non-null    str    \n",
      " 18  Collection_Attempts      500 non-null    int64  \n",
      " 19  Collection_Method        500 non-null    str    \n",
      " 20  Legal_Action_Taken       500 non-null    str    \n",
      "dtypes: float64(4), int64(8), str(9)\n",
      "memory usage: 82.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('loan-recovery.csv')\n",
    "print(\"Original Data Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c612070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # log helper\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(f\"[INFO] {msg}\")\n",
    "\n",
    "    # 1. standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    log(\"Standardized column names.\")\n",
    "\n",
    "    # 2. remove exact duplicates\n",
    "    dup_count = df.duplicated().sum()\n",
    "    if dup_count > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        log(f\"Removed {dup_count} duplicate rows.\")\n",
    "\n",
    "    # 3. trim and lowercase all string (object) values\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "    log(\"Standardized string columns (lowercase + trimmed).\")\n",
    "\n",
    "    # 4. detect missing values (including blanks and placeholders)\n",
    "    placeholder_values = ['n/a', 'na', '--', '-', 'none', 'null', '', 'nan']\n",
    "    df.replace(placeholder_values, np.nan, inplace=True)\n",
    "    null_report = df.isnull().sum()\n",
    "    null_report = null_report[null_report > 0]\n",
    "    if not null_report.empty:\n",
    "        log(f\"Missing values found in columns:\\n{null_report}\")\n",
    "\n",
    "    # 5. flag constant columns\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_cols:\n",
    "        log(f\"Constant columns (consider removing): {constant_cols}\")\n",
    "\n",
    "    # 6. flag high cardinality categorical columns\n",
    "    high_card_cols = [col for col in df.select_dtypes(include='object') if df[col].nunique() > 100]\n",
    "    if high_card_cols:\n",
    "        log(f\"High-cardinality columns (consider encoding strategies): {high_card_cols}\")\n",
    "\n",
    "    # 7. detect numeric outliers using IQR\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    outlier_report = {}\n",
    "    for col in num_cols:\n",
    "        q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)][col].count()\n",
    "        if outliers > 0:\n",
    "            outlier_report[col] = outliers\n",
    "    if outlier_report:\n",
    "        log(f\"Potential numeric outliers detected:\\n{outlier_report}\")\n",
    "\n",
    "    # 8. convert applicable columns to category\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        n_unique = df[col].nunique()\n",
    "        if n_unique < len(df) * 0.05:\n",
    "            df[col] = df[col].astype('category')\n",
    "    log(\"Converted suitable object columns to category dtype.\")\n",
    "\n",
    "    log(\"Data cleaning complete.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d790468",
   "metadata": {},
   "source": [
    "### Here’s what this Python function does:\n",
    "\n",
    "Copies the data to keep your original safe.\n",
    "Standardizes column names (lowercase, no spaces).\n",
    "Removes duplicate rows if any.\n",
    "Cleans string columns (trims and lowercases all text).\n",
    "Handles missing values (turns things like –, N/A into NaN).\n",
    "Reports missing values in each column.\n",
    "Flags constant columns (same value in all rows).\n",
    "Identifies high-cardinality text columns (too many unique values).\n",
    "Detects numeric outliers using the IQR method.\n",
    "Converts low-unique text columns to category type.\n",
    "Logs every step if verbose=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806d2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Standardized column names.\n",
      "[INFO] Standardized string columns (lowercase + trimmed).\n",
      "[INFO] High-cardinality columns (consider encoding strategies): ['borrower_id', 'loan_id']\n",
      "[INFO] Potential numeric outliers detected:\n",
      "{'outstanding_loan_amount': np.int64(3), 'monthly_emi': np.int64(35), 'num_missed_payments': np.int64(21), 'collection_attempts': np.int64(40)}\n",
      "[INFO] Converted suitable object columns to category dtype.\n",
      "[INFO] Data cleaning complete.\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   borrower_id              500 non-null    str     \n",
      " 1   age                      500 non-null    int64   \n",
      " 2   gender                   500 non-null    category\n",
      " 3   employment_type          500 non-null    category\n",
      " 4   monthly_income           500 non-null    int64   \n",
      " 5   num_dependents           500 non-null    int64   \n",
      " 6   loan_id                  500 non-null    str     \n",
      " 7   loan_amount              500 non-null    int64   \n",
      " 8   loan_tenure              500 non-null    int64   \n",
      " 9   interest_rate            500 non-null    float64 \n",
      " 10  loan_type                500 non-null    category\n",
      " 11  collateral_value         500 non-null    float64 \n",
      " 12  outstanding_loan_amount  500 non-null    float64 \n",
      " 13  monthly_emi              500 non-null    float64 \n",
      " 14  payment_history          500 non-null    category\n",
      " 15  num_missed_payments      500 non-null    int64   \n",
      " 16  days_past_due            500 non-null    int64   \n",
      " 17  recovery_status          500 non-null    category\n",
      " 18  collection_attempts      500 non-null    int64   \n",
      " 19  collection_method        500 non-null    category\n",
      " 20  legal_action_taken       500 non-null    category\n",
      "dtypes: category(7), float64(4), int64(8), str(2)\n",
      "memory usage: 58.4 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madna\\AppData\\Local\\Temp\\ipykernel_7704\\3220206765.py:23: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  for col in df.select_dtypes(include='object'):\n",
      "C:\\Users\\madna\\AppData\\Local\\Temp\\ipykernel_7704\\3220206765.py:41: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  high_card_cols = [col for col in df.select_dtypes(include='object') if df[col].nunique() > 100]\n",
      "C:\\Users\\madna\\AppData\\Local\\Temp\\ipykernel_7704\\3220206765.py:60: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  for col in df.select_dtypes(include='object'):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('loan-recovery.csv')\n",
    "clean_df = clean_dataframe(df)\n",
    "print(clean_df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
